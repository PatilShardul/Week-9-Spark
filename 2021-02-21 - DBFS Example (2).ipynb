{"cells":[{"cell_type":"markdown","source":["## Overview\n\nThis notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n\nThis notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96816ed7-b08a-4ca3-abb9-f99880c3535d"}}},{"cell_type":"code","source":["from pyspark.sql.functions import *"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b8fe474-03de-44ad-89b5-fac5059c5231"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["dbutils.widgets.text(name=\"storage_account\", defaultValue= \" \", label= \"Storage Account String\")\ndbutils.widgets.text(name=\"container_name\", defaultValue= \" \", label= \"container Name\")\ndbutils.widgets.text(name=\"mount_path\",defaultValue=\" \",label=\"Mount Path\")\ndbutils.widgets.text(name=\"storage_account_key\", defaultValue= \"Ends with ==\", label= \"Storage Account key\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a48fd390-fc8e-4a3a-8e62-5020c077b63a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e4451df-5e70-4ec4-bc29-3be55a03d811"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Create a spark dataframe in the "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62edcf2c-1e60-4c5a-8b31-e074cd53759a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# File location and type\nfile_location = \"/FileStore/tables/computerlogs/CpuLogData2019*.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"true\"\nfirst_row_is_header = \"true\"\ndelimiter = \",\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\ndf = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location)\n\ndf = df.select(\"DateTime\",\"keyboard\",\"mouse\",\"user_name\")\\\n        .withColumn('Date', split(df['DateTime'], ' ').getItem(0))\\\n        .withColumn('Time', split(df['DateTime'], ' ').getItem(1))\\\n        .withColumn('DateTime', to_timestamp(df['DateTime']))\nprint(df.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6482be4c-f067-47c9-b0ac-35c938b94601"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["storage_account_name =dbutils.widgets.get(\"storage_account\")\n# Azure Storage Account Key\nstorage_account_key =dbutils.widgets.get(\"storage_account_key\")\n\n# Azure Storage Account Source Container\ncontainer = dbutils.widgets.get(\"container_name\")\nmount_path=dbutils.widgets.get(\"mount_path\")\n# Set the configuration details to read/write\nspark.conf.set(\"fs.azure.account.key.{0}.blob.core.windows.net\".format(storage_account_name), storage_account_key)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"60e20bfc-3698-4474-a424-4cd12edb8abc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["dbutils.fs.mount(\n   source = \"wasbs://{0}@{1}.blob.core.windows.net\".format(container, storage_account_name),\n   mount_point = mount_path,\n   extra_configs = {\"fs.azure.account.key.{0}.blob.core.windows.net\".format(storage_account_name): storage_account_key}\n  )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe2eea55-3cdb-42ba-a18e-99ca27569eba"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ExecutionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3348328071542889&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span>    source <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;wasbs://{0}@{1}.blob.core.windows.net&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>container<span class=\"ansi-blue-fg\">,</span> storage_account_name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>    mount_point <span class=\"ansi-blue-fg\">=</span> mount_path<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\">    </span>extra_configs <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">&#34;fs.azure.account.key.{0}.blob.core.windows.net&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>storage_account_name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span> storage_account_key<span class=\"ansi-blue-fg\">}</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>   )\n\n<span class=\"ansi-green-fg\">/local_disk0/tmp/1614313033070-0/dbutils.py</span> in <span class=\"ansi-cyan-fg\">f_with_exception_handling</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    322</span>                     exc<span class=\"ansi-blue-fg\">.</span>__context__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    323</span>                     exc<span class=\"ansi-blue-fg\">.</span>__cause__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-fg\">--&gt; 324</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> exc\n<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">return</span> f_with_exception_handling\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span> \n\n<span class=\"ansi-red-fg\">ExecutionError</span>: An error occurred while calling o339.mount.\n: shaded.databricks.org.apache.hadoop.fs.azure.AzureException: java.lang.StringIndexOutOfBoundsException: String index out of range: 7\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.createAzureStorageSession(AzureNativeFileSystemStore.java:1037)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.initialize(AzureNativeFileSystemStore.java:488)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem.initialize(NativeAzureFileSystem.java:1352)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.verifyAzureFileSystem(DBUtilsCore.scala:502)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:451)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.StringIndexOutOfBoundsException: String index out of range: 7\n\tat java.lang.String.charAt(String.java:658)\n\tat hadoop_azure_shaded.com.microsoft.azure.storage.core.Base64.decode(Base64.java:84)\n\tat hadoop_azure_shaded.com.microsoft.azure.storage.StorageCredentialsAccountAndKey.&lt;init&gt;(StorageCredentialsAccountAndKey.java:81)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.connectUsingConnectionStringCredentials(AzureNativeFileSystemStore.java:877)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.createAzureStorageSession(AzureNativeFileSystemStore.java:1022)\n\t... 15 more\n</div>","errorSummary":"shaded.databricks.org.apache.hadoop.fs.azure.AzureException: java.lang.StringIndexOutOfBoundsException: String index out of range: 7","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ExecutionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3348328071542889&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span>    source <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;wasbs://{0}@{1}.blob.core.windows.net&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>container<span class=\"ansi-blue-fg\">,</span> storage_account_name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>    mount_point <span class=\"ansi-blue-fg\">=</span> mount_path<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\">    </span>extra_configs <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">&#34;fs.azure.account.key.{0}.blob.core.windows.net&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>storage_account_name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span> storage_account_key<span class=\"ansi-blue-fg\">}</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>   )\n\n<span class=\"ansi-green-fg\">/local_disk0/tmp/1614313033070-0/dbutils.py</span> in <span class=\"ansi-cyan-fg\">f_with_exception_handling</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    322</span>                     exc<span class=\"ansi-blue-fg\">.</span>__context__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    323</span>                     exc<span class=\"ansi-blue-fg\">.</span>__cause__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-fg\">--&gt; 324</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> exc\n<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">return</span> f_with_exception_handling\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span> \n\n<span class=\"ansi-red-fg\">ExecutionError</span>: An error occurred while calling o339.mount.\n: shaded.databricks.org.apache.hadoop.fs.azure.AzureException: java.lang.StringIndexOutOfBoundsException: String index out of range: 7\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.createAzureStorageSession(AzureNativeFileSystemStore.java:1037)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.initialize(AzureNativeFileSystemStore.java:488)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem.initialize(NativeAzureFileSystem.java:1352)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.verifyAzureFileSystem(DBUtilsCore.scala:502)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:451)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.StringIndexOutOfBoundsException: String index out of range: 7\n\tat java.lang.String.charAt(String.java:658)\n\tat hadoop_azure_shaded.com.microsoft.azure.storage.core.Base64.decode(Base64.java:84)\n\tat hadoop_azure_shaded.com.microsoft.azure.storage.StorageCredentialsAccountAndKey.&lt;init&gt;(StorageCredentialsAccountAndKey.java:81)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.connectUsingConnectionStringCredentials(AzureNativeFileSystemStore.java:877)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.createAzureStorageSession(AzureNativeFileSystemStore.java:1022)\n\t... 15 more\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Create a view or table\n\ntemp_table_name = \"CpuLogData\"\n\ndf.createOrReplaceTempView(temp_table_name)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd82bb99-1479-4d5c-be10-8c36df0f1d44"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["highest_average_active_user_df = sqlContext.sql(\"select user_name,from_unixtime(ROUND(((count(*)*5)*60)/6,2),'HH:mm') as average_active_time_in_hours from `CpuLogData` where ( keyboard != 0 or mouse != 0 ) group by user_name order by average_active_time_in_hours desc\")\ndisplay(highest_average_active_user_df)\nhighest_average_active_user_df.write.option(\"header\",True) \\\n .csv(\"/mnt/sparklogfile/highest_average_active_user_df.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"93b619a9-68ee-426a-b4d3-3144b0c86151"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["lowest_average_active_user_df = sqlContext.sql(\"select user_name,from_unixtime(ROUND(((count(*)*5)*60)/6,2),'HH:mm')  as average_active_time_in_hours from `CpuLogData` where (keyboard != 0 or mouse != 0 ) group by user_name order by average_active_time_in_hours limit 1\")\ndisplay(lowest_average_active_user_df)\nlowest_average_active_user_df.write.option(\"header\",True) \\\n .csv(\"/mnt/sparklogfile/lowest_average_active_user_df.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"93cf43a9-c70d-464c-8e22-73a81ca569fa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Highest Average Idle hour \nhighest_average_idle_user_df = sqlContext.sql(\"select user_name,from_unixtime(ROUND(((count(*)*5)*60)/6,2),'HH:mm') as average_idle_time_in_hours from `CpuLogData` where (keyboard == 0 and mouse == 0 ) group by user_name order by average_idle_time_in_hours desc limit 1 \")\ndisplay(highest_average_idle_user_df)\nhighest_average_idle_user_df.write.option(\"header\",True) \\\n .csv(\"/mnt/sparklogfile/highest_average_idle_user_df.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db9631f6-bb4a-42ca-8a3c-0d48af932331"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["\ndaily_session_start_time_df = sqlContext.sql(\"select Date,to_timestamp(min(DateTime)) as DateTime from CpuLogData group by Date order by Date\")\ntemp_table_name = \"view_session_start_time\"\ndaily_session_start_time_df.createOrReplaceTempView(temp_table_name)\ndisplay(daily_session_start_time_df)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"20d453ce-9426-4ae8-a996-1e3ac0ef01fd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["daily_login_time_df = sqlContext.sql(\"select user_name,Date,min(DateTime) as Datetime from `CpuLogData` where (keyboard != 0 or mouse != 0) group by user_name,Date order by Date\")\ntemp_table_name = \"view_daily_login_time\"\ndaily_login_time_df.createOrReplaceTempView(temp_table_name)\ndisplay(daily_login_time_df)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"75735561-591b-4d7c-9640-41700add9767"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["late_users_df = sqlContext.sql(\"select lut.user_name,\\\nConcat(cast(Round((Sum(lut.TimeDifference)/60)/6,2) AS INT),' Hour , ',Floor(Round((((Sum(lut.TimeDifference)/60)/6)%1)*60)),' Min') as average_late_time_in_hours, count(*) as daily_late_count from (Select lt.user_name,(unix_timestamp(lt.DateTime)-unix_timestamp(st.DateTime))/(60) as TimeDifference from view_daily_login_time as lt,view_session_start_time as st where lt.Date == st.Date) as lut where lut.TimeDifference != 0 group by lut.user_name order by average_late_time_in_hours desc\")\ndisplay(late_users_df)\nlate_users_df.write.option(\"header\",True) \\\n .csv(\"/mnt/sparklogfile/late_users_df.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2ba170a3-f269-4f91-b6da-403d788636e7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"2021-02-21 - DBFS Example (2)","dashboards":[],"language":"python","widgets":{"container_name":{"nuid":"93ed9e80-68cd-496a-a81e-7ae21ad25db1","currentValue":" ","widgetInfo":{"widgetType":"text","name":"container_name","defaultValue":" ","label":"container Name","options":{"widgetType":"text","validationRegex":null}}},"storage_account_key":{"nuid":"875696b5-89d5-4d02-8974-c15c0a72e043","currentValue":"","widgetInfo":{"widgetType":"text","name":"storage_account_key","defaultValue":"Ends with ==","label":"Storage Account key","options":{"widgetType":"text","validationRegex":null}}},"storage_account":{"nuid":"133e06ff-ebc1-4134-a7ee-4139401ddddd","currentValue":"","widgetInfo":{"widgetType":"text","name":"storage_account","defaultValue":" ","label":"Storage Account String","options":{"widgetType":"text","validationRegex":null}}},"mount_path":{"nuid":"6f5e4f91-ee09-4f4b-9864-207da16e87c7","currentValue":"","widgetInfo":{"widgetType":"text","name":"mount_path","defaultValue":" ","label":"Mount Path","options":{"widgetType":"text","validationRegex":null}}}},"notebookOrigID":2980103652348237}},"nbformat":4,"nbformat_minor":0}
